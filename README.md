<<<<<<< HEAD
## **Trenchy: A Context-Aware Code-Mixed E-Commerce Chatbot**

Trenchy is a Hinglish-aware, product-contextual customer-support chatbot built with  Rasa 3.x , a  custom FastAPI backend , and a frontend website integrated via rasa-webchat.

It supports:

* Code-mixed Hinglish understanding
* Product-aware reasoning (auto-context from product pages)
* Order + refund workflow support
* Sentiment handling + human handoff
* SQLite product/order DB
* Full e-commerce QA flow

This README explains exactly how to install, run, and test the entire system.

# **1. Installation & Virtual Environment Setup**

**Python version required: `3.9.6`**

Rasa does **NOT** work with Python 3.10 or above.

### **Create virtual environment**

```bash
python3.9 -m venv venv
source venv/bin/activate      # macOS/Linux
venv\Scripts\activate         # Windows
```

### **Install project dependencies**

Your project contains:

* `requirements.txt` â†’ **main Rasa project**
* `backend/requirements.txt` â†’ **backend API**

Install main dependencies:

```bash
pip install -r requirements.txt
```

# **2. Training the Rasa Model**

Before running anything:

```bash
rasa train
```

This creates the latest conversational model under `/models`.

# **3. Running the Project (3-terminal setup)**

Trenchy uses  **three terminals** :

## **Terminal 1 â€” Run the Rasa Action Server**

Run from the  *project root* , where `actions.py` is located:

```bash
source venv/bin/activate
rasa run actions
```

You should see:

```
Action server is up and running.
```

## **Terminal 2 â€” Run the Rasa Assistant (interactive shell)**

If you want to test the bot  *inside the terminal* :

```bash
source venv/bin/activate
rasa shell
```

You can use this for debugging, intent tests, policy tests, etc.

## **Terminal 3 â€” Run Rasa for Web Integration**

This is required for the  **frontend HTML pages** :

```bash
source venv/bin/activate
rasa run --enable-api --cors "*"
```

This opens:

```
http://localhost:5005
```

and allows:

* rasa-webchat widget
* metadata sending
* socket.io communication
* frontend product context injection

# **4. Running the Backend API (Product + Order Database)**

Your backend lives in:

```
trenchy-backend/
```

### **Install backend dependencies**

```bash
cd trenchy-backend
pip install -r requirements.txt
```

### **Run the backend API**

```bash
uvicorn main:app --reload --port 8000
```

This serves endpoints like:

```
GET http://localhost:8000/products
GET http://localhost:8000/product?id=TS017
GET http://localhost:8000/orders/OD12345
```

These endpoints are used by:

* **Frontend product pages**
* **Custom Rasa actions** for stock & order queries
* **Context-aware reasoning logic**

# 5. Running the Frontend (Website)

Open:

```
index.html
```

Then right-click to open with Live Server on VS Code.

### Product pages automatically pass metadata:

* `product_id`
* `page_url`

to Rasa through:

```js
event.metadata = {
   product_id: pid,
   page_url: url
};
```

# **6. Testing the System**

Try queries like:

### **Product reasoning**

* â€œTell me about this productâ€
* â€œGive me details about thisâ€
* â€œCan you describe this item?â€

### **Order tracking**

* â€œTrack order OD90001â€
* â€œCancel my orderâ€
* â€œRefund status kya hai?â€

### **Hinglish queries**

* â€œrefund policy kya haiâ€
* â€œshipping options kya haiâ€

### **Sentiment**

* â€œAwesomeâ€
* â€œPerfect, thank you!â€

### **Out of scope**

* â€œWhatâ€™s the weather?â€

Everything should respond correctly if metadata + backend + Rasa are running.

# **7. Troubleshooting**

### **Metadata is missing**

Check the frontend's:

```js
onSocketEvent.user_uttered
```

### **Backend not responding**

Ensure:

```bash
uvicorn main:app --reload --port 8000
```

is running.

### **Model isnâ€™t updating**

Retrain:

```bash
rasa train
```

### **Rasa wonâ€™t start**

Ensure Python is  **3.9.6** .

# **8. Summary of Commands**

### Train model

```bash
rasa train
```

### Terminal 1

```bash
rasa run actions
```

### Terminal 2 (Optional)

```bash
rasa shell
```

### Terminal 3

```bash
rasa run --enable-api --cors "*"
```

### Backend API

```bash
cd trenchy-backend
uvicorn main:app --reload --port 8000
```

**Then start index.html using Live Server.**

---
=======
# Trenchy
A metadata-driven, Rasa-powered conversational assistant that understands Hinglish and provides intelligent, product-aware customer support for e-commerce platforms.

Trenchy is an end-to-end e-commerce support chatbot designed for the Indian market, where customers frequently communicate in code-mixed Hinglish (Hindi + English).
Instead of responding generically, Trenchy uses context-awareness, product metadata, and custom Rasa actions to deliver precise, human-like support.

The system integrates:

A multi-page web frontend (Men, Women, Kids, Misc, Product Pages)

Socket.IO metadata injection (product_id + page_url)

A FastAPI backend serving product + order data

A Rasa NLU + Core model for reasoning, entity extraction, and intent detection

Custom actions for stock lookup, recommendations, order status, cancellation, etc.

Trenchy brings real-time, product-aware reasoning to online shopping.

ðŸš€ Key Features

ðŸ§  1. Hinglish NLU

Understands mixed-language queries such as:

â€œye washable hai?â€

â€œisko M size milega?â€

â€œis shirt ka material kya hai?â€

ðŸ“¦ 2. Product-Aware Reasoning (Context Injection)

When a user views a product page:
âž¡ï¸ the browser automatically injects the product ID + URL into each chatbot message
âž¡ï¸ the bot knows exactly which product the user is asking about

ðŸ›’ 3. Order & Refund Management

Supports:

Tracking orders

Canceling orders

Reinstating orders

Checking refund status

Changing delivery address

â¤ï¸ 4. Sentiment Detection + Human Handoff

Negative sentiment triggers escalation

Positive sentiment triggers upsell flow

Handles frustration gracefully

ðŸ·ï¸ 5. Recommendations Engine

Shows related products based on category.

ðŸ“¦ 6. Backend API (FastAPI)

Serves:

/products

/products/{id}

/orders/{order_id}
â€¦all used by the chatbot and frontend.

ðŸ§± System Architecture
 User (Browser)
       â”‚
       â”‚ 1. Message + product_id metadata
       â–¼
ðŸ—¨ï¸ Rasa Webchat Widget (Socket.IO)
       â”‚
       â–¼
ðŸ¤– Rasa NLU  â†’ Intent recognition + Hinglish entity extraction
       â”‚
       â–¼
ðŸ§  Rasa Core (Rules + Policies)
       â”‚
       â–¼
âš™ï¸ Custom Actions (Python)
       â”‚
       â–¼
ðŸ—„ï¸ FastAPI Backend â†’ SQLite DB (products, orders)
       â”‚
       â–¼
ðŸ“¦ Product / Order Results â†’ Back to Rasa â†’ Back to User

ðŸ› ï¸ Tech Stack

Rasa 3.x (NLU + Core + RulePolicy + TEDPolicy)

Python 3.9.6

FastAPI + Uvicorn

SQLite

JavaScript, HTML, CSS

Socket.IO

rasa-webchat widget

VADER sentiment analysis

ðŸ“¥ Installation & Setup
1ï¸âƒ£ Clone the Project
git clone https://github.com/yourusername/trenchy.git
cd trenchy

2ï¸âƒ£ Create & Activate Virtual Environment (Python 3.9.6)
python3.9 -m venv venv
source venv/bin/activate     # macOS/Linux
venv\Scripts\activate        # Windows

3ï¸âƒ£ Install Rasa Project Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Train the Rasa Model
rasa train

ðŸƒâ€â™‚ï¸ Running the Project

Trenchy uses three terminals (plus backend).

ðŸŸ¦ Terminal 1 â€” Rasa Action Server
source venv/bin/activate
rasa run actions

ðŸŸ© Terminal 2 â€” Rasa Shell (for testing)
source venv/bin/activate
rasa shell

ðŸŸ§ Terminal 3 â€” Rasa Server (Frontend Uses This)
source venv/bin/activate
rasa run --enable-api --cors "*"

ðŸŸª Backend API (FastAPI)

The backend folder is trenchy-backend.

Install backend dependencies:
cd trenchy-backend
pip install -r requirements.txt

Run backend:
uvicorn main:app --reload --port 8000


Backend endpoints:

GET /products
GET /products/{id}
GET /orders/{order_id}

ðŸŒ Frontend

Open:

index.html


or serve it:

cd frontend
python3 -m http.server 8080


Product pages automatically send metadata to Rasa using:

event.metadata = {
   product_id,
   page_url,
};

ðŸ“‚ Project Structure
trenchy/
â”‚
â”œâ”€â”€ actions.py
â”œâ”€â”€ sentiment_analyzer.py
â”œâ”€â”€ domain.yml
â”œâ”€â”€ nlu.yml
â”œâ”€â”€ rules.yml
â”œâ”€â”€ stories.yml
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ trenchy-backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ products.db
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ product.html
â”‚   â”œâ”€â”€ products/
â”‚   â”‚   â”œâ”€â”€ men.html
â”‚   â”‚   â”œâ”€â”€ women.html
â”‚   â”‚   â”œâ”€â”€ kids.html
â”‚   â”‚   â””â”€â”€ misc.html
â”‚   â””â”€â”€ images/
â”‚
â””â”€â”€ README.md

ðŸ”® Future Work

Integrate LLM-based RAG for more natural conversational responses

Add WhatsApp/Instagram messaging support

Build a shopping cart flow inside the chatbot

Improve recommendation engine using collaborative filtering

Deploy on cloud (Render / HuggingFace Spaces / Railway)

ðŸ“ License

MIT License

ðŸ“š Citation

If you use this project in research, please cite:

@project{trenchy,
  title={Trenchy: A Context-Aware, Code-Mixed Conversational Agent for E-Commerce},
  year={2025},
  author={Dhar, Rushali}
}
>>>>>>> b677ecd998a71bbbb01b67c876f88c39251f2eb2
